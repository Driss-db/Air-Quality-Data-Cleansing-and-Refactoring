# Task 6

On this project, we had recorded data of levels of various air borne pollutants. His data is recorder by UK government in order to protect our health. To do so, the government stets two objectives to monitor the air quality. The first is the concentration of NO2 in the air, averaged over a period of one hour. The second is the concentration of NO2 in the air, averaged over a period of a year. <br>
On the first task, we cropped and cleaned the data. Thus, by deleting the records before the 1st January 2010 since it is the data we are interested in, deleting records with missing siteID, and deleting any mismatches between the siteID and the location since every siteID was attached to a location. The solution we worked with to get rid of the mismatches is creating a dictionary holding as keys the siteID and as values the location, the defined a function that returns the mismatches. <br>
On the second task, we created an Entity Relationship (ER) model to hold the data. We created three tables “readings”, “schema” and “stations”, with a relationship between “readings” and “stations”. The foreign key in the “readings” table is siteID. Then, by using the forward engineering feature, an sql file was created which holds the schema and implements the database. <br>
On the third task, we wrote a python script that creates and populate the data base on Mysql Workbench. We used “mysql” python library in order to connect and write on the database. Since sql doesn’t understand NaN values, we replaced them by “NULL”. Then, we executed sql queries to populate the database with the help of the sql script generated by the previous task. Then, we wrote a python script that generates a sql file holding the first 100 inserts. <br>
For the fourth task, we wrote three sql queries where we had to query data from different tables and join them. The first query returns date time, station name, and the highest recorded value of nitrogen oxide (NOx) in 2019, which means we had to select the columns we needed from different tables for the specific year 2019 using the year() function on the date/time column. The second one returns the mean value of PM2.5 and VPM2.5 by each station in 2019 for readings on or near 08:00 hours, where we use the mean() function. Finally, the last query was about extending the previous one to show these values for all stations on a range of years between 2010 and 2019, which meant that rather than assigning a specific year for the output of the function year() on date/time column, we put it in the range we needed. <br>
For the fifth task, we modelled the data for a specific monitor to a NoSQL data model to implement the selected database import the data. The station we chose was ‘Old Market’ and used MongoDB to implement the Database. Moreover, we wrote a python script, which creates and populate the data. <br>
In order to visualize our data, we can use the date time column in order to visualize the evolution of the concentration of any pollutants in the air. Moreover, we can create a heat map showing for each hour or year the concentration of any pollutants in the air in each station. Furthermore, we can analyse the time series in order to detect seasonality and peak periods. <br>
We learned in this assignment how to crop and clean our data, create an ER model and using forward engineering feature, populate our sql database using python, querying the data, modelling, populating and querying a NOsql database.



```python

```
